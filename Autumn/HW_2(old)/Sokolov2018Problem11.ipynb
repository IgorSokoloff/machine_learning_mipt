{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ДЗ 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Соколов Игорь\n",
    "### Группа 573"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Задача 11\n",
    "Нарисовать траекторию пошагового спуска к минимуму градиентного метода и имитации отжига. Сравнить их работу при поиске мимимума тестовой функции"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"func.png\" width=linewidth align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Будем решать задачу при $N=2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import time\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib as mpl\n",
    "#import seaborn as sns\n",
    "import scipy \n",
    "\n",
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML \n",
    "import timeit\n",
    "#import numdifftools as nd\n",
    "import pandas as pd\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from ipywidgets import FloatProgress\n",
    "from IPython.display import display\n",
    "\n",
    "import sys\n",
    "from scipy._lib.six import callable, xrange\n",
    "import go_benchmark as gb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "За основу функции, реализующую алгоритм метода имитации, отжига была взята **anneal** из библиотеки **scipy** (https://goo.gl/Q1y4pY).\n",
    "Была незначительно модернизирована."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division, print_function, absolute_import\n",
    "\n",
    "import numpy\n",
    "from numpy import (asarray, tan, exp, ones, squeeze, sign,\n",
    "        all, log, sqrt, pi, shape, array, minimum, where, random, deprecate)\n",
    "from scipy.optimize import OptimizeResult\n",
    "\n",
    "\n",
    "__all__ = ['anneal']\n",
    "\n",
    "_double_min = numpy.finfo(float).min\n",
    "_double_max = numpy.finfo(float).max\n",
    "\n",
    "\n",
    "class base_schedule(object):\n",
    "    def __init__(self):\n",
    "        self.dwell = 20\n",
    "        self.learn_rate = 0.5\n",
    "        self.lower = -10\n",
    "        self.upper = 10\n",
    "        self.Ninit = 50\n",
    "        self.accepted = 0\n",
    "        self.tests = 0\n",
    "        self.feval = 0\n",
    "        self.k = 0\n",
    "        self.T = None\n",
    "\n",
    "    def init(self, **options):\n",
    "        self.__dict__.update(options)\n",
    "        self.lower = asarray(self.lower)\n",
    "        self.lower = where(self.lower == numpy.NINF, -_double_max, self.lower)\n",
    "        self.upper = asarray(self.upper)\n",
    "        self.upper = where(self.upper == numpy.PINF, _double_max, self.upper)\n",
    "        self.k = 0\n",
    "        self.accepted = 0\n",
    "        self.feval = 0\n",
    "        self.tests = 0\n",
    "\n",
    "    def getstart_temp(self, best_state):\n",
    "        \"\"\" Find a matching starting temperature and starting parameters vector\n",
    "        i.e. find x0 such that func(x0) = T0.\n",
    "        Parameters\n",
    "        ----------\n",
    "        best_state : _state\n",
    "            A _state object to store the function value and x0 found.\n",
    "        Returns\n",
    "        -------\n",
    "        x0 : array\n",
    "            The starting parameters vector.\n",
    "        \"\"\"\n",
    "\n",
    "        assert(not self.dims is None)\n",
    "        lrange = self.lower\n",
    "        urange = self.upper\n",
    "        fmax = _double_min\n",
    "        fmin = _double_max\n",
    "        for _ in range(self.Ninit):\n",
    "            x0 = random.uniform(size=self.dims)*(urange-lrange) + lrange\n",
    "            fval = self.func(x0, *self.args)\n",
    "            self.feval += 1\n",
    "            if fval > fmax:\n",
    "                fmax = fval\n",
    "            if fval < fmin:\n",
    "                fmin = fval\n",
    "                best_state.cost = fval\n",
    "                best_state.x = array(x0)\n",
    "\n",
    "        self.T0 = (fmax-fmin)*1.5\n",
    "        return best_state.x\n",
    "\n",
    "    def accept_test(self, dE):\n",
    "        T = self.T\n",
    "        self.tests += 1\n",
    "        if dE < 0:\n",
    "            self.accepted += 1\n",
    "            return 1\n",
    "        p = exp(-dE*1.0/self.boltzmann/T)\n",
    "        if (p > random.uniform(0.0, 1.0)):\n",
    "            self.accepted += 1\n",
    "            return 1\n",
    "        return 0\n",
    "\n",
    "    def update_guess(self, x0):\n",
    "        pass\n",
    "\n",
    "    def update_temp(self, x0):\n",
    "        pass\n",
    "\n",
    "\n",
    "#  A schedule due to Lester Ingber\n",
    "class fast_sa(base_schedule):\n",
    "    def init(self, **options):\n",
    "        self.__dict__.update(options)\n",
    "        if self.m is None:\n",
    "            self.m = 1.0\n",
    "        if self.n is None:\n",
    "            self.n = 1.0\n",
    "        self.c = self.m * exp(-self.n * self.quench)\n",
    "\n",
    "    def update_guess(self, x0):\n",
    "        x0 = asarray(x0)\n",
    "        u = squeeze(random.uniform(0.0, 1.0, size=self.dims))\n",
    "        T = self.T\n",
    "        y = sign(u-0.5)*T*((1+1.0/T)**abs(2*u-1)-1.0)\n",
    "        xc = y*(self.upper - self.lower)\n",
    "        xnew = x0 + xc\n",
    "        return xnew\n",
    "\n",
    "    def update_temp(self):\n",
    "        self.T = self.T0*exp(-self.c * self.k**(self.quench))\n",
    "        self.k += 1\n",
    "        return\n",
    "\n",
    "\n",
    "class cauchy_sa(base_schedule):\n",
    "    def update_guess(self, x0):\n",
    "        x0 = asarray(x0)\n",
    "        numbers = squeeze(random.uniform(-pi/2, pi/2, size=self.dims))\n",
    "        xc = self.learn_rate * self.T * tan(numbers)\n",
    "        xnew = x0 + xc\n",
    "        return xnew\n",
    "\n",
    "    def update_temp(self):\n",
    "        self.T = self.T0/(1+self.k)\n",
    "        self.k += 1\n",
    "        return\n",
    "\n",
    "\n",
    "class boltzmann_sa(base_schedule):\n",
    "    def update_guess(self, x0):\n",
    "        std = minimum(sqrt(self.T) * ones(self.dims),\n",
    "                      (self.upper - self.lower) / 3.0 / self.learn_rate)\n",
    "        x0 = asarray(x0)\n",
    "        xc = squeeze(random.normal(0, 1.0, size=self.dims))\n",
    "\n",
    "        xnew = x0 + xc*std*self.learn_rate\n",
    "        return xnew\n",
    "\n",
    "    def update_temp(self):\n",
    "        self.k += 1\n",
    "        self.T = self.T0 / log(self.k+1.0)\n",
    "        return\n",
    "\n",
    "\n",
    "class _state(object):\n",
    "    def __init__(self):\n",
    "        self.x = None\n",
    "        self.cost = None\n",
    "\n",
    "\n",
    "# TODO:\n",
    "#     allow for general annealing temperature profile\n",
    "#     in that case use update given by alpha and omega and\n",
    "#     variation of all previous updates and temperature?\n",
    "\n",
    "# Simulated annealing\n",
    "\n",
    "@deprecate(message='Deprecated in scipy 0.14.0, use basinhopping instead')\n",
    "def anneal(func, x0, args=(), schedule='fast', full_output=0,\n",
    "           T0=None, Tf=1e-12, maxeval=None, maxaccept=None, maxiter=400,\n",
    "           boltzmann=1.0, learn_rate=0.5, feps=1e-6, quench=1.0, m=1.0, n=1.0,\n",
    "           lower=-100, upper=100, dwell=50, disp=True):\n",
    "    opts = {'schedule': schedule,\n",
    "            'T0': T0,\n",
    "            'Tf': Tf,\n",
    "            'maxfev': maxeval,\n",
    "            'maxaccept': maxaccept,\n",
    "            'maxiter': maxiter,\n",
    "            'boltzmann': boltzmann,\n",
    "            'learn_rate': learn_rate,\n",
    "            'ftol': feps,\n",
    "            'quench': quench,\n",
    "            'm': m,\n",
    "            'n': n,\n",
    "            'lower': lower,\n",
    "            'upper': upper,\n",
    "            'dwell': dwell,\n",
    "            'disp': disp}\n",
    "\n",
    "    res, X, T = _minimize_anneal(func, x0, args, **opts)\n",
    "    return res, X, T\n",
    "    '''\n",
    "    if full_output:\n",
    "        return res['x'], X,res['fun'], res['T'], res['nfev'], res['nit'], \\\n",
    "            res['accept'], res['status']\n",
    "    else:\n",
    "        return res, X\n",
    "    '''\n",
    "\n",
    "def _minimize_anneal(func, x0, args=(),\n",
    "                     schedule='fast', T0=None, Tf=1e-12, maxfev=None,\n",
    "                     maxaccept=None, maxiter=400, boltzmann=1.0,\n",
    "                     learn_rate=0.5, ftol=1e-6, quench=1.0, m=1.0, n=1.0,\n",
    "                     lower=-100, upper=100, dwell=50, disp=False,\n",
    "                     **unknown_options):\n",
    "    #_check_unknown_options(unknown_options)\n",
    "    maxeval = maxfev\n",
    "    feps = ftol\n",
    "\n",
    "    x0 = asarray(x0)\n",
    "    \n",
    "    X = []\n",
    "    X.append(x0)\n",
    "    \n",
    "    T = []\n",
    "    \n",
    "\n",
    "    lower = asarray(lower)\n",
    "    upper = asarray(upper)\n",
    "\n",
    "    schedule = eval(schedule+'_sa()')\n",
    "    #   initialize the schedule\n",
    "    schedule.init(dims=shape(x0), func=func, args=args, boltzmann=boltzmann,\n",
    "                  T0=T0, learn_rate=learn_rate, lower=lower, upper=upper,\n",
    "                  m=m, n=n, quench=quench, dwell=dwell)\n",
    "\n",
    "    current_state, last_state, best_state = _state(), _state(), _state()\n",
    "    if T0 is None:\n",
    "        x0 = schedule.getstart_temp(best_state)\n",
    "    else:\n",
    "        best_state.x = None\n",
    "        best_state.cost = numpy.Inf\n",
    "    \n",
    "    last_state.x = asarray(x0).copy()\n",
    "    fval = func(x0, *args)\n",
    "    schedule.feval += 1\n",
    "    last_state.cost = fval\n",
    "    if last_state.cost < best_state.cost:\n",
    "        best_state.cost = fval\n",
    "        best_state.x = asarray(x0).copy()\n",
    "    schedule.T = schedule.T0\n",
    "    T.append(schedule.T)\n",
    "    fqueue = [100, 300, 500, 700]\n",
    "    iters = 0\n",
    "    while 1:\n",
    "        for n in xrange(dwell):\n",
    "            current_state.x = schedule.update_guess(last_state.x) \n",
    "            current_state.cost = func(current_state.x, *args)\n",
    "            schedule.feval += 1\n",
    "\n",
    "            dE = current_state.cost - last_state.cost\n",
    "            if schedule.accept_test(dE):\n",
    "                last_state.x = current_state.x.copy()\n",
    "                last_state.cost = current_state.cost\n",
    "                if last_state.cost < best_state.cost:\n",
    "                    best_state.x = last_state.x.copy()\n",
    "                    best_state.cost = last_state.cost\n",
    "        schedule.update_temp()\n",
    "        \n",
    "        X.append(best_state.x)\n",
    "        T.append(schedule.T)\n",
    "        iters += 1\n",
    "        # Stopping conditions\n",
    "        # 0) last saved values of f from each cooling step\n",
    "        #     are all very similar (effectively cooled)\n",
    "        # 1) Tf is set and we are below it\n",
    "        # 2) maxeval is set and we are past it\n",
    "        # 3) maxiter is set and we are past it\n",
    "        # 4) maxaccept is set and we are past it\n",
    "\n",
    "        fqueue.append(squeeze(last_state.cost))\n",
    "        fqueue.pop(0)\n",
    "        af = asarray(fqueue)*1.0\n",
    "        if all(abs((af-af[0])/af[0]) < feps):\n",
    "            retval = 0\n",
    "            if abs(af[-1]-best_state.cost) > feps*10:\n",
    "                retval = 5\n",
    "                if disp:\n",
    "                    print(\"Warning: Cooled to %f at %s but this is not\"\n",
    "                          % (squeeze(last_state.cost),\n",
    "                             str(squeeze(last_state.x)))\n",
    "                          + \" the smallest point found.\")\n",
    "            break\n",
    "        if (Tf is not None) and (schedule.T < Tf):\n",
    "            retval = 1\n",
    "            break\n",
    "        if (maxeval is not None) and (schedule.feval > maxeval):\n",
    "            retval = 2\n",
    "            break\n",
    "        if (iters > maxiter):\n",
    "            if disp:\n",
    "                print(\"Warning: Maximum number of iterations exceeded.\")\n",
    "            retval = 3\n",
    "            break\n",
    "        if (maxaccept is not None) and (schedule.accepted > maxaccept):\n",
    "            retval = 4\n",
    "            break\n",
    "\n",
    "    result = OptimizeResult(x=best_state.x, fun=best_state.cost,\n",
    "                            T=schedule.T, nfev=schedule.feval, nit=iters,\n",
    "                            accept=schedule.accepted, status=retval,\n",
    "                            success=(retval <= 1),\n",
    "                            message={0: 'Points no longer changing',\n",
    "                                     1: 'Cooled to final temperature',\n",
    "                                     2: 'Maximum function evaluations',\n",
    "                                     3: 'Maximum cooling iterations reached',\n",
    "                                     4: 'Maximum accepted query locations reached',\n",
    "                                     5: 'Final point not the minimum amongst '\n",
    "                                        'encountered points'}[retval])\n",
    "    return result, X, T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "func = lambda x: obj_fun.evaluator(x)\n",
    "dfunc = lambda x: -np.sin(np.sqrt(np.abs(x))) - (x**2)*np.cos(np.sqrt(np.abs(x)))*1.0/(2*np.abs(x)**(3.0/2.0))\n",
    "\n",
    "def gradient_descent(f, df, x0, args=(), mu=0.01, n_iter=10000, eps=1e-4):\n",
    "    x_ar = []\n",
    "    x_ar.append(x0)\n",
    "    x = x0\n",
    "    nit = 0\n",
    "    while 1:\n",
    "        nit += 1\n",
    "        x = x - mu*df(x, *args)\n",
    "        x_ar.append(x)\n",
    "        \n",
    "        if nit>= n_iter or np.linalg.norm(x=x,ord=2) <= eps:\n",
    "            break\n",
    "    return x_ar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = gradient_descent(f, df, np.array(obj_fun.generator()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-500.0, 500.0)"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj_fun.bounds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-500.        , -479.59183673, -459.18367347, -438.7755102 ,\n",
       "       -418.36734694, -397.95918367, -377.55102041, -357.14285714,\n",
       "       -336.73469388, -316.32653061, -295.91836735, -275.51020408,\n",
       "       -255.10204082, -234.69387755, -214.28571429, -193.87755102,\n",
       "       -173.46938776, -153.06122449, -132.65306122, -112.24489796,\n",
       "        -91.83673469,  -71.42857143,  -51.02040816,  -30.6122449 ,\n",
       "        -10.20408163,   10.20408163,   30.6122449 ,   51.02040816,\n",
       "         71.42857143,   91.83673469,  112.24489796,  132.65306122,\n",
       "        153.06122449,  173.46938776,  193.87755102,  214.28571429,\n",
       "        234.69387755,  255.10204082,  275.51020408,  295.91836735,\n",
       "        316.32653061,  336.73469388,  357.14285714,  377.55102041,\n",
       "        397.95918367,  418.36734694,  438.7755102 ,  459.18367347,\n",
       "        479.59183673,  500.        ])"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500.0"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj_fun.bounds[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nres, X_1, T= anneal(func, x_i, schedule='fast',\\n                        full_output=True, \\n                        maxiter=1000, \\n                        T0 = func(x_i),\\n                        lower=np.array (obj_fun.bounds[0]),\\n                        upper=np.array (obj_fun.bounds[1]), \\n                        dwell=250, disp=True)\\n\\ntraj1, = ax1.plot([], [], 'r', animated=True, label='GD')\\n\\nX_2 = gradient_descent(f, df, np.array(obj_fun.generator()))\\n\\nX_1 = np.array(X_1)\\nX_2 = np.array(X_2)\\n\\ntraj2, = ax1.plot([], [], 'w', animated=True, label='SGD')\\n\\nax1.legend()\\n\\ndef init():\\n    return traj1, traj2\\n\\ndef update(frame):\\n    traj1.set_data(X_1[:frame, 0], X_1[:frame, 1])\\n    traj2.set_data(X_2[:frame, 0], X_2[:frame, 1])\\n    return traj1, traj2\\n\\nf.set_size_inches(12, 5)\\n#f.suptitle(f'2 routers, {nsteps} steps')\\n          \\nFuncAnimation(f, update, frames=range(max(len(X_1),len(X_2))), interval=120,\\n                    init_func=init, blit=True)\""
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xf3a8ef0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib.animation import FuncAnimation\n",
    "from functools import partial\n",
    "plt.rcParams[\"animation.html\"] = \"html5\"\n",
    "plt.rcParams['animation.ffmpeg_path'] = 'C:\\\\ffmpeg\\\\bin\\\\ffmpeg.exe'\n",
    "\n",
    "obj_fun = gb.Schwefel26()\n",
    "\n",
    "\n",
    "w1 = np.linspace(start=obj_fun.bounds[0][0], \n",
    "                 stop=obj_fun.bounds[0][1],\n",
    "                 num=500)\n",
    "\n",
    "w2 = np.linspace(start=obj_fun.bounds[1][0], \n",
    "                 stop=obj_fun.bounds[1][1], \n",
    "                 num=500)\n",
    "\n",
    "#x = np.random.rand(n)*l\n",
    "p = np.array([ np.array([func(np.array(w1_, w2_)) for w2_ in w2]) for w1_ in w1]) \n",
    "\n",
    "f, ax1 = plt.subplots(1, 1, sharey=True)\n",
    "\n",
    "c1 = ax1.contourf(w1, w2, p, cmap=\"viridis\")\n",
    "plt.colorbar(c1, ax = ax1)\n",
    "ax1.set_title('P')\n",
    "'''\n",
    "res, X_1, T= anneal(func, x_i, schedule='fast',\n",
    "                        full_output=True, \n",
    "                        maxiter=1000, \n",
    "                        T0 = func(x_i),\n",
    "                        lower=np.array (obj_fun.bounds[0]),\n",
    "                        upper=np.array (obj_fun.bounds[1]), \n",
    "                        dwell=250, disp=True)\n",
    "\n",
    "traj1, = ax1.plot([], [], 'r', animated=True, label='GD')\n",
    "\n",
    "X_2 = gradient_descent(f, df, np.array(obj_fun.generator()))\n",
    "\n",
    "X_1 = np.array(X_1)\n",
    "X_2 = np.array(X_2)\n",
    "\n",
    "traj2, = ax1.plot([], [], 'w', animated=True, label='SGD')\n",
    "\n",
    "ax1.legend()\n",
    "\n",
    "def init():\n",
    "    return traj1, traj2\n",
    "\n",
    "def update(frame):\n",
    "    traj1.set_data(X_1[:frame, 0], X_1[:frame, 1])\n",
    "    traj2.set_data(X_2[:frame, 0], X_2[:frame, 1])\n",
    "    return traj1, traj2\n",
    "\n",
    "f.set_size_inches(12, 5)\n",
    "#f.suptitle(f'2 routers, {nsteps} steps')\n",
    "          \n",
    "FuncAnimation(f, update, frames=range(max(len(X_1),len(X_2))), interval=120,\n",
    "                    init_func=init, blit=True)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, 0.0]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
