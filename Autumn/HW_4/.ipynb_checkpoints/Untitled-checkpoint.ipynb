{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.utils import np_utils\n",
    "from keras.layers.core import Dense, Activation, Dropout, Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['font.family'] = 'serif'\n",
    "plt.rcParams['font.serif'] = 'FreeSerif'\n",
    "plt.rcParams['lines.linewidth'] = 2\n",
    "plt.rcParams['lines.markersize'] = 12\n",
    "plt.rcParams['xtick.labelsize'] = 24\n",
    "plt.rcParams['ytick.labelsize'] = 24\n",
    "plt.rcParams['legend.fontsize'] = 24\n",
    "plt.rcParams['axes.titlesize'] = 36\n",
    "plt.rcParams['axes.labelsize'] = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.read_csv(\"./data_sets/train.csv\")\n",
    "data_test = pd.read_csv(\"./data_sets/test.csv\")\n",
    "(X,y) = (data_train.drop(columns=[\"label\"]), data_train[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,random_state=17)\n",
    "X_train = X_train.astype('float32') \n",
    "X_test = X_test.astype('float32')\n",
    "X_train = X_train.values.reshape(X_train.shape[0], 1, 28, 28)\n",
    "X_test = X_test.values.reshape(X_test.shape[0], 1, 28, 28)\n",
    "X_train /= 255 # Normalise data to [0, 1] range\n",
    "X_test /= 255 # Normalise data to [0, 1] range\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = plt.figure(figsize=(10, 10))\n",
    "\n",
    "ax = plt.subplot(2, 2, 1)\n",
    "ax.imshow(X_train[0].reshape([28, 28]))\n",
    "\n",
    "ax = plt.subplot(2, 2, 2)\n",
    "i = np.random.randint(0, X_train.shape[0], 1)\n",
    "ax.imshow(X_train[i].reshape([28, 28]))\n",
    "\n",
    "ax = plt.subplot(2, 2, 3)\n",
    "i = np.random.randint(0, X_train.shape[0], 1)\n",
    "ax.imshow(X_train[i].reshape([28, 28]))\n",
    "\n",
    "ax = plt.subplot(2, 2, 4)\n",
    "i = np.random.randint(0, X_train.shape[0], 1)\n",
    "ax.imshow(X_train[i].reshape([28, 28]))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128 # in each iteration, we consider 128 training examples at once\n",
    "num_epochs = 15 # we iterate twenty times over the entire training set\n",
    "hidden_size = 512 # there will be 512 neurons in both hidden layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(30, (5, 5), input_shape=(1, 28, 28), activation='relu',data_format='channels_first'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(60, (3, 3), activation='relu',data_format='channels_first'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(120, activation='sigmoid'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(60, activation='sigmoid'))\n",
    "model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', # using the cross-entropy loss function\n",
    "              optimizer='Adam', # using the Adam optimiser\n",
    "              metrics=['accuracy']) # reporting the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=num_epochs,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test,y_test, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Draw Plots of errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,7))\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper right')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.figure(figsize=(10,7))\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper right')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "learning plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_sizes = np.arange(1000, 10000, 1000)\n",
    "set_sizes = np.hstack((set_sizes, list(range(10, 100, 10))))\n",
    "set_sizes = np.hstack((set_sizes, list(range(100, 1000, 100))))\n",
    "set_sizes = np.sort(set_sizes)\n",
    "accuracy_metric = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for size in set_sizes:\n",
    "    print(size)\n",
    "    used_indices = np.random.choice(np.arange(X_train.shape[0]), size, replace=False)\n",
    "    model.fit(X_train[used_indices, :], y_train[used_indices, :],\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=num_epochs,\n",
    "                    verbose=0,\n",
    "                    validation_split=0.3)\n",
    "    accuracy_metric.append(model.evaluate(X_test,y_test, verbose=1))\n",
    "    print(accuracy_metric[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_loss = np.asarray(accuracy_metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,7))\n",
    "plt.plot(set_sizes, accuracy_loss[:, 1])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Set size')\n",
    "plt.legend(['Train'], loc='upper right')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.figure(figsize=(10,7))\n",
    "plt.plot(set_sizes, accuracy_loss[:, 0])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Set Size')\n",
    "plt.legend(['Train'], loc='upper right')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding a noize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_noisy_x(X_train, mean, stddev):\n",
    "    n_imgs = X_train.shape[0]\n",
    "    n_chan = X_train.shape[1]\n",
    "    n_rows = X_train.shape[2]\n",
    "    n_cols = X_train.shape[3]\n",
    "    if stddev == 0:\n",
    "        noise = np.zeros((n_imgs, n_chan, n_rows, n_cols))\n",
    "    else:\n",
    "        noise = np.random.normal(mean, stddev/255., \n",
    "                                     (n_imgs, n_chan, n_rows, n_cols))\n",
    "    noisy_X = X_train + noise\n",
    "    noisy_X = np.clip(noisy_X, 0., 1.)\n",
    "    return noisy_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = plt.figure(figsize=(10, 10))\n",
    "for i in range(1, 5):\n",
    "    ax = plt.subplot(2, 2, i)\n",
    "    ax.imshow(get_noisy_x(X_train, mean=0, stddev=10*(i - 1))[0].reshape([28, 28]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noises = [x for x in range(0, 110, 10)]\n",
    "histories = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for noise in noises:\n",
    "    print(noise)\n",
    "    histories.append(model.fit(get_noisy_x(X_train, mean=0, stddev=noise), y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=num_epochs,\n",
    "                    verbose=0,\n",
    "                    validation_split=0.3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Draw plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 15))\n",
    "i = 0\n",
    "for history in histories:  \n",
    "    plt.plot(history.history['acc'], label=\"Noise =\" + str(noises[i]/ 255))\n",
    "    i+= 1\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.title('Model accuracy')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 15))\n",
    "i = 0\n",
    "for history in histories:  \n",
    "    plt.plot(history.history['loss'], label=\"Noise =\" + str(noises[i]/255))\n",
    "    i+= 1\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.title('Model loss')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
